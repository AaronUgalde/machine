{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3cec506",
   "metadata": {},
   "source": [
    "### Instrucciones\n",
    "1. Sin utilizar las bibliotecas de *scikit-learn* para regresión lineal, elabora un programa en Python que implemente **BGD monovariable sin sesgo**.\n",
    "\n",
    "### Entrada\n",
    "- Archivo `casas.csv`\n",
    "- Número de iteraciones\n",
    "- Peso inicial\n",
    "- Valor de α (learning rate)\n",
    "\n",
    "### Procedimiento\n",
    "- Divide `casas.csv` en:\n",
    "  - 70% para entrenamiento\n",
    "  - 30% para pruebas  \n",
    "  Usando los parámetros:  \n",
    "  `shuffle=True` y `random_state=0`.\n",
    "\n",
    "### Salida\n",
    "(Ver ejemplo de la **Figura 1**)\n",
    "\n",
    "- Peso en cada iteración calculado con el conjunto de entrenamiento.\n",
    "- Valores `y_test`.\n",
    "- Valores `y_pred` en cada iteración.\n",
    "- Error de estimación:  \n",
    "\n",
    "  $\n",
    "  \\sigma = \\sum_{i=1}^{n} (y_{pred_i} - y_{test_i})\n",
    "  $\n",
    "\n",
    "- **Gráfica 1**\n",
    "  - Distribución de los datos de prueba\n",
    "  - Valores `y_pred` en cada iteración\n",
    "- **Gráfica 2**\n",
    "  - Error de estimación de cada iteración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b06132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46da18b",
   "metadata": {},
   "source": [
    "$$Y = XW$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16e5cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, weights):\n",
    "    return X.dot(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7248f8",
   "metadata": {},
   "source": [
    "  $$\n",
    "  \\sigma = \\sum_{i=1}^{n} (y_{pred_i} - y_{test_i})\n",
    "  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf745abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(y_true, y_pred):\n",
    "    \"\"\"Error: suma de valores absolutos de la diferencia\"\"\"\n",
    "    return float(np.sum(np.abs(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f702202",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial \\sigma}{\\partial w} = (w \\times X - Y) \\cdot X$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d981d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(index, W, X, Y):\n",
    "    #print(\"X: \", X.T[index])\n",
    "    #print(\"W: \", W, \" W index: \", W[0][index])\n",
    "    #print(Y)\n",
    "    Y_pred = W[index] * X.T[index]  # Predicción\n",
    "    return np.dot((Y_pred - Y), X.T[index])  # Gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1b74448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_bueno(index, W, X, Y):\n",
    "    \"\"\"\n",
    "    Gradiente para W[index] en regresión multivariable\n",
    "    Fórmula: grad_i = (1/m) * X[:, i].T @ (X @ W - Y)\n",
    "    \"\"\"\n",
    "    m = len(Y)\n",
    "    Y_pred = predict(X, W)  # Predicción con TODOS los pesos\n",
    "    residual = Y_pred - Y\n",
    "    return np.dot(X[:, index], residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da710229",
   "metadata": {},
   "source": [
    "$$\\Delta w = -2 \\times \\frac{\\partial \\sigma}{\\partial w} \\times \\alpha$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "916107f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment(index, W, X, Y, alpha):\n",
    "    grad = gradient(index, W, X, Y)\n",
    "    return - 2 * alpha * grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a222f06",
   "metadata": {},
   "source": [
    "$$w = w + \\Delta w$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0344ac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(W, X, Y, alpha):\n",
    "    increments = np.array([increment(i, W, X, Y, alpha) for i in range(len(W))])\n",
    "    W += increments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63f2bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    1 / (1 + np.e ** x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33b6f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_descent(X_train, Y_train, X_test, Y_test, initial_weights,\n",
    "                           learning_rate=1e-6, n_iterations=1000):\n",
    "    \"\"\"BGD multivariable sin sesgo\"\"\"\n",
    "    W = np.array(initial_weights)\n",
    "    n_features = X_train.shape[1]\n",
    "    if W.shape[0] != n_features:\n",
    "        raise ValueError(\"Inicial_weights debe tener longitud igual a n_features\")\n",
    "\n",
    "    weights_history = []\n",
    "    errors_history = []\n",
    "    ypreds_history = []\n",
    "    for iteration in range(n_iterations):\n",
    "        update_weights(W, X_train, Y_train, learning_rate)\n",
    "        \n",
    "        # Guardar copia completa del vector de pesos\n",
    "        weights_history.append(W.copy())\n",
    "        \n",
    "        ypred_test = sigmoid(predict(X_test, W))                       # (m_test,)\n",
    "        err_test = error(Y_test, ypred_test)\n",
    "\n",
    "        errors_history.append(err_test)\n",
    "        ypreds_history.append(ypred_test.copy())\n",
    "\n",
    "        print(\"=== ITREATION: \", iteration, \" ===\")\n",
    "        print(\"prediction: \", ypred_test)\n",
    "        print(\"error: \", err_test)\n",
    "        print(\"pesos: \", W)\n",
    "        \n",
    "    return W, weights_history, errors_history, ypreds_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4a84ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (2, 3), X_test: (1, 3), Y_train: (2,), Y_test: (1,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mX_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, X_test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_test.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Y_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY_train.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Y_test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY_test.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Entrenamiento (ahora guardamos predicciones en test por iteración)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m best_weights, weights_history, errors_history, ypreds_history = batch_gradient_descent(\n\u001b[32m     20\u001b[39m     X_train, Y_train, X_test, Y_test,\n\u001b[32m     21\u001b[39m     initial_weights,\n\u001b[32m     22\u001b[39m     learning_rate=learning_rate,\n\u001b[32m     23\u001b[39m     n_iterations=n_iterations,\n\u001b[32m     24\u001b[39m )\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Predicción final (última iteración)\u001b[39;00m\n\u001b[32m     27\u001b[39m Y_pred_final = ypreds_history[-\u001b[32m1\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mbatch_gradient_descent\u001b[39m\u001b[34m(X_train, Y_train, X_test, Y_test, initial_weights, learning_rate, n_iterations)\u001b[39m\n\u001b[32m     16\u001b[39m weights_history.append(W.copy())\n\u001b[32m     18\u001b[39m ypred_test = sigmoid(predict(X_test, W))                       \u001b[38;5;66;03m# (m_test,)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m err_test = error(Y_test, ypred_test)\n\u001b[32m     21\u001b[39m errors_history.append(err_test)\n\u001b[32m     22\u001b[39m ypreds_history.append(ypred_test.copy())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36merror\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34merror\u001b[39m(y_true, y_pred):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Error: suma de valores absolutos de la diferencia\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(np.sum(np.abs(y_pred - y_true)))\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for -: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "# ---------------- main (configurar como en tu script) ----------------\n",
    "dataset = pd.read_csv('Dataset_multivariable.csv')\n",
    "n_features = dataset.shape[1] - 1\n",
    "initial_weights = np.array([0.1, 0.2, 0.3])\n",
    "learning_rate = 0.01\n",
    "n_iterations = 1\n",
    "\n",
    "# Split (los .values ya convierten a ndarray)\n",
    "X = dataset.iloc[:, :-1].values\n",
    "Y = dataset.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.25, shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}, Y_train: {Y_train.shape}, Y_test: {Y_test.shape}\")\n",
    "\n",
    "# Entrenamiento (ahora guardamos predicciones en test por iteración)\n",
    "best_weights, weights_history, errors_history, ypreds_history = batch_gradient_descent(\n",
    "    X_train, Y_train, X_test, Y_test,\n",
    "    initial_weights,\n",
    "    learning_rate=learning_rate,\n",
    "    n_iterations=n_iterations,\n",
    ")\n",
    "\n",
    "# Predicción final (última iteración)\n",
    "Y_pred_final = ypreds_history[-1]\n",
    "\n",
    "print(\"\\n=== RESULTADOS FINALES ===\")\n",
    "print(f\"Pesos finales: {best_weights}\")\n",
    "print(f\"Primeros valores y_test: {Y_test[:10]}\")\n",
    "print(f\"Primeros valores y_pred (última iter): {Y_pred_final[:10]}\")\n",
    "print(f\"Error final en test: {error(Y_test, Y_pred_final):.6f}\")\n",
    "\n",
    "# ---------------------- GRAFICAS ----------------------\n",
    "\n",
    "# 1) Gráfica: y_test (puntos) + y_pred por iteración (líneas)\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "m_test = len(Y_test)\n",
    "indices = np.arange(m_test)\n",
    "\n",
    "# scatter de reales\n",
    "plt.scatter(indices, Y_test, label='y real (test)', alpha=0.8, s=40)\n",
    "\n",
    "# seleccionar iteraciones a mostrar (para no saturar)\n",
    "max_lines_to_plot = 8\n",
    "if n_iterations <= max_lines_to_plot:\n",
    "    iter_indices = list(range(n_iterations))\n",
    "else:\n",
    "    iter_indices = np.unique(np.round(np.linspace(0, n_iterations - 1, max_lines_to_plot)).astype(int)).tolist()\n",
    "\n",
    "for idx, it in enumerate(iter_indices):\n",
    "    ypred_it = ypreds_history[it]\n",
    "    alpha = 0.4 if it != (n_iterations - 1) else 1.0\n",
    "    lw = 1.0 if it != (n_iterations - 1) else 2.0\n",
    "    # dibujamos como línea conectando orden de índices\n",
    "    plt.plot(indices, ypred_it, label=f'iter {it}', alpha=alpha, linewidth=lw)\n",
    "\n",
    "plt.xlabel('Índice de muestra (test)')\n",
    "plt.ylabel('Valor')\n",
    "plt.title('y real (puntos) y predicciones por iteración (líneas)')\n",
    "plt.legend(fontsize='small')\n",
    "plt.grid(alpha=0.2)\n",
    "\n",
    "# 2) Error vs iteración (historial de test)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(np.arange(len(errors_history)), errors_history, marker='o')\n",
    "plt.xlabel('Iteración')\n",
    "plt.ylabel('Error (suma abs) en test')\n",
    "plt.title('Error de estimación por iteración (test)')\n",
    "plt.grid(alpha=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
